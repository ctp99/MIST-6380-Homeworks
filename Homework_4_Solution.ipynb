{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "Your submission will be tested with the code tester. It is important to follow these instructions to ensure your work tests properly.\n",
    "\n",
    "- Do not change the content of the cells under __SETUP__ and __TESTS__\n",
    "- Work only in the __YOUR WORK__ area\n",
    "- Rename the notebook with your group at the end (subsitute XX with your group number).\n",
    "- Assign the results of each numbered question to the appropriate test variable. For example, the answer of `1.` should be assigned to `test_1`\n",
    "- Rounding: use the supplied function `hround` to round decimal numbers when instructed. It's important to use this function because there are [multiple ways to round numbers in Python](https://www.knowledgehut.com/blog/programming/python-rounding-numbers) and they may not result in the same value that the tester is testing against.\n",
    "- Ensure your run the cells under __SETUP__ before you run your work\n",
    "- Before you submit your work, ensure you clean up your notebook. Your notebook has to run without an error in order to be tested. The easiest way to ensure is to `Kernel->Restart & Run All`\n",
    "- Answers are provided in along with this notebook in eLC (look a picture named `solution_key`) for your convenience\n",
    "- You will need to write a program to calculate the answers. Setting the answers to be their correct values without solving them is considered *hardcoding* and will result in zero grade for the assignment as well as a potential academic honesty violation.\n",
    "- You can also test your submission using [the online code tester](https://notebook-tester.safadi-puzzler.com/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hanisaf/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT EDIT OR CHANGE THE CONTENT OF THIS CELL\n",
    "scenario = 0\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import nltk;nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hround(number):\n",
    "    return round(number, 2 - scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1=test_2=test_3=test_4=test_5=test_6=test_7=test_8=test_9=test_10=0.0\n",
    "test_11=test_12=test_13=test_14=test_15=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, we have data from the [100 Resilient Cities](https://www.rockefellerfoundation.org/100-resilient-cities/#:~:text=Overview%20In%202013%2C%20The%20Rockefeller%20Foundation%20pioneered%20100,a%20roadmap%20to%20resilience%20along%20four%20main%20pathways%3A?msclkid=5705866aaaaa11ec85d9402890b45f8f). The data contains 30 documents from 30 cities outlining their strategies for urban resilience. We are going to focus on text and network analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "      <th>ENTITIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Australia</td>\n",
       "      <td>﻿PEOPLE ARE\\nAT THE HEART OF ALL CITIES\\nA res...</td>\n",
       "      <td>{'LOCATION': ['Collingwood', 'Sri Lankan', 'So...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>﻿100 Resilient Cities - Pioneered by The Rocke...</td>\n",
       "      <td>{'ORGANIZATION': ['IPCC', 'PARTNERS World Bank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Medelin</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>﻿A CITY THAT TRANSFORMS ITSELF FOR ITS PEOPLE\\...</td>\n",
       "      <td>{'LOCATION': ['Colombia', 'Proantioquia', 'l.A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vejles</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>﻿Letter from the Mayor\\nArne Sigtenbjerggaard\\...</td>\n",
       "      <td>{'PERSON': ['Torben Christensen', 'Burgos', 'J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>﻿MAURICIO RODAS\\nMAYOR OF THE METROPOLITAN DIS...</td>\n",
       "      <td>{'LOCATION': ['Mexico City Cuntlupo', 'Quito',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             city    country  \\\n",
       "0       Melbourne  Australia   \n",
       "1  Rio de Janeiro     Brazil   \n",
       "2         Medelin   Colombia   \n",
       "3          Vejles    Denmark   \n",
       "4           Quito    Ecuador   \n",
       "\n",
       "                                                text  \\\n",
       "0  ﻿PEOPLE ARE\\nAT THE HEART OF ALL CITIES\\nA res...   \n",
       "1  ﻿100 Resilient Cities - Pioneered by The Rocke...   \n",
       "2  ﻿A CITY THAT TRANSFORMS ITSELF FOR ITS PEOPLE\\...   \n",
       "3  ﻿Letter from the Mayor\\nArne Sigtenbjerggaard\\...   \n",
       "4  ﻿MAURICIO RODAS\\nMAYOR OF THE METROPOLITAN DIS...   \n",
       "\n",
       "                                            ENTITIES  \n",
       "0  {'LOCATION': ['Collingwood', 'Sri Lankan', 'So...  \n",
       "1  {'ORGANIZATION': ['IPCC', 'PARTNERS World Bank...  \n",
       "2  {'LOCATION': ['Colombia', 'Proantioquia', 'l.A...  \n",
       "3  {'PERSON': ['Torben Christensen', 'Burgos', 'J...  \n",
       "4  {'LOCATION': ['Mexico City Cuntlupo', 'Quito',...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('resillient_cities.json')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: text analytics\n",
    "\n",
    "1. Report the unique city names in a sorted list\n",
    "\n",
    "2. Report the unique country names in a sorted list\n",
    "\n",
    "3. What are the top five frequent words in `text`, return the results in a sorted list\n",
    "\n",
    "Now we will do some text analysis. Because NLP algorithms are computationally expensive, we are going to do them on one text (so that you and the tester save time evaluating the notebook)\n",
    "\n",
    "4. Let us focus on the `text` of the city of `Glasgow`, extract the text from the data frame then perform sentiment analysis with `TextBlob`. Which sentence in this text has the lowest (most negative) polarity?\n",
    "\n",
    "5. Using `spacy`, perform named entity detection on Glasgow's text. Now focus on organization `ORG` entities. What are the top 5 frequent organization entities. Return the results in a series sorted by that frequency.\n",
    "\n",
    "Now, we want to benefit from the named entities to learn more about what was discussed in these documents. To save time, I am giving you the extracted named entities in a the column `ENTITIES`. The entities  are organized as a dictionary where the keys are entity types and the values are the instances of these entities from the text.\n",
    "\n",
    "6. Let us perform the same analysis as before but on all documents. Extract the `ORGANIZATION` entities of all documents from the column `ENTITIES`. Report the five popular organization entities in a series sorted by frequencies.\n",
    "\n",
    "## Part 2: network analytics\n",
    "\n",
    "We will now use network analytics to better understand relationships among these entities and the cities.\n",
    "\n",
    "7. Let us start easy. Using `networkx` create an undirected graph then add an edge from each city to each country based on the data in the columns `city` and `coutry` (no `ENTITIES` involved in this question). Report in a tuple the number of nodes and number of edges in this network.\n",
    "\n",
    "8. using the `degrees` function, report the degrees of nodes in this network.\n",
    "\n",
    "9. Which node has the highest degree?\n",
    "\n",
    "10. Let us focus our attentions to organization entities. We want to better understand organizations' involvment with cities. Create an undirected network the edges represent links between each city and every organization entity pertaining to this city. How many nodes and edges are there in the network? return a tuple.\n",
    "\n",
    "11. Using the above-created network, return a sorted list of cities associated with `United Nations`\n",
    "\n",
    "12. We want to create a network similar to the previous one but a directed network this time. Create a `DiGraph` and add directed edges from each city to each organization showing in the `ENTITIES` of that city. We want to rank organizations based on their involvement with multiple cities. To do this look at the `in_degree` property of the created network. Sort based on the frequency of association (descending). Show the first 10 organizations with their indegrees as a list of tuples (again sorted based on that frequency).\n",
    "\n",
    "13. As you can see, some organizations show as acronyms. Select only organization names with multiple words. Show the top ten in the same format as above.\n",
    "\n",
    "14. In this last analysis, we want to identify potentially influential people. We define influence as being mentioned in the same text where a number containing the keyword `million` or the keyword `billion` is mentioned. Focus on the `ENTITIES` column and select only rows containing the keywords (million or billion) in a `MONEY` entity type. Then create an undirected network and associate each city to each person name from the `PERSON` list in `ENTITIES`. So this network has an association between cities and people mentioned in the text only when high money numbers are discussed (hence influence). Show the number of nodes and edges in a tuple.\n",
    "\n",
    "15. Calculate closeness centrality and show the top 15 nodes with highest colesness centrality (in sorted order) with the following exclusions.\n",
    "\n",
    "- exclude any name with `berkowitz` in any casing since `Michael Berkowitz` was the lead researcher on this project\n",
    "- exclude any one word names\n",
    "- exclude any name matching a city name (from the column city) in the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = sorted(set(data.city))\n",
    "test_2 = sorted(set(data.country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.Series((data.text + \" \").sum().split())\n",
    "test_3 = sorted(words.value_counts().index[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_negative_polarity \n",
    "text = data.loc[data.city=='Glasgow', 'text'].iloc[0]\n",
    "blob = TextBlob(text)\n",
    "glasgow_sentiment = [(sent.raw, sent.sentiment.polarity, sent.sentiment.subjectivity) for sent in blob.sentences]\n",
    "test_4 = sorted(glasgow_sentiment, key=lambda t: t[1])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "org_entities = [ent.text for ent in doc.ents if ent.label_ == 'ORG']\n",
    "test_5 = pd.Series(org_entities).value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = data['ENTITIES'].str['ORGANIZATION'].sum()\n",
    "test_6 = pd.Series(locations).value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = nx.Graph()\n",
    "net1.add_edges_from(data[['city', 'country']].values)\n",
    "test_7 = len(net1.nodes), len(net1.edges)\n",
    "test_8 = degrees =  net1.degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_9 = max(degrees, key=lambda e: e[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network of the cities to organizations\n",
    "data['organizations'] = data.ENTITIES.str['ORGANIZATION']\n",
    "edges = data[['city', 'organizations']].explode(column='organizations').values\n",
    "net2 = nx.Graph()\n",
    "net2.add_edges_from(edges)\n",
    "test_10 = len(net2.nodes), len(net2.edges)\n",
    "#city of athens\n",
    "test_11 = sorted(net2['United Nations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net3 = nx.DiGraph()\n",
    "net3.add_edges_from(edges)\n",
    "indegrees = sorted(net3.in_degree, key = lambda e: e[1], reverse=True)\n",
    "test_12 = indegrees[:10]\n",
    "test_13 = [e for e in indegrees if len(e[0].split()) > 1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#people of influence\n",
    "data['money'] = data.ENTITIES.str['MONEY']\n",
    "data['person'] = data.ENTITIES.str['PERSON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = data[['city', 'money', 'person']].explode('money', ignore_index=True).dropna()\n",
    "step2 = step1[step1.money.str.contains(\"million\") | step1.money.str.contains(\"billion\")]\n",
    "step3 = step2.explode('person')\n",
    "edges = step3[['city', 'person']].values\n",
    "net4 = nx.Graph()\n",
    "net4.add_edges_from(edges)\n",
    "test_14 = len(net4.nodes), len(net4.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "closeness = nx.closeness_centrality(net4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_closeness = sorted(closeness.items(), key=lambda e: e[1], reverse=True)\n",
    "test_15 = [n for n, c in sorted_closeness if (len(n.split()) > 1) and ('berkowitz' not in n.lower()) and (n not in set(data.city))][:15]\n",
    "test_15 = sorted(test_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amman',\n",
       " 'Athens',\n",
       " 'Bangkok',\n",
       " 'Berkeley',\n",
       " 'Boulder',\n",
       " 'Bristol',\n",
       " 'Byblos',\n",
       " 'Dakar',\n",
       " 'El Paso',\n",
       " 'Glasgow',\n",
       " 'Greater Christchurch',\n",
       " 'Medelin',\n",
       " 'Melbourne',\n",
       " 'Mexico City',\n",
       " 'New Orleans',\n",
       " 'Norfolk',\n",
       " 'Oakland',\n",
       " 'Pittsburgh',\n",
       " 'Quito',\n",
       " 'Ramallah',\n",
       " 'Rio de Janeiro',\n",
       " 'Rotterdam',\n",
       " 'San Francisco',\n",
       " 'Santa Fe',\n",
       " 'Semarang',\n",
       " 'Surat',\n",
       " 'Thessaloniki',\n",
       " 'Toyama',\n",
       " 'Vejles',\n",
       " 'Wellington']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEST 1\n",
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australia',\n",
       " 'Brazil',\n",
       " 'Colombia',\n",
       " 'Denmark',\n",
       " 'Ecuador',\n",
       " 'Greece',\n",
       " 'India',\n",
       " 'Indonesia',\n",
       " 'Japan',\n",
       " 'Jordan',\n",
       " 'Lebanon',\n",
       " 'Mexico',\n",
       " 'Netherlands',\n",
       " 'New Zealand',\n",
       " 'Palestine',\n",
       " 'Senegal',\n",
       " 'Thailand',\n",
       " 'UK',\n",
       " 'USA']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 2\n",
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'in', 'of', 'the', 'to']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 3\n",
    "test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is no getting away from the fact that these are difficult times for Glasgow.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 4\n",
    "test_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Glasgow                       26\n",
       "GEAPP                          4\n",
       "The Rockefeller Foundation     2\n",
       "IDENTIFY                       2\n",
       "Scottish Enterprise            2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 5\n",
    "test_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rockefeller Foundation        22\n",
       "Resilience Strategy           20\n",
       "The Rockefeller Foundation    20\n",
       "NGOs                          18\n",
       "CRF                           16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 6\n",
    "test_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 30)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 7\n",
    "test_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DegreeView({'Melbourne': 1, 'Australia': 1, 'Rio de Janeiro': 1, 'Brazil': 1, 'Medelin': 1, 'Colombia': 1, 'Vejles': 1, 'Denmark': 1, 'Quito': 1, 'Ecuador': 1, 'Athens': 1, 'Greece': 2, 'Thessaloniki': 1, 'Surat': 1, 'India': 1, 'Semarang': 1, 'Indonesia': 1, 'Toyama': 1, 'Japan': 1, 'Amman': 1, 'Jordan': 1, 'Byblos': 1, 'Lebanon': 1, 'Mexico City': 1, 'Mexico': 1, 'Rotterdam': 1, 'Netherlands': 1, 'Greater Christchurch': 1, 'New Zealand': 2, 'Wellington': 1, 'Ramallah': 1, 'Palestine': 1, 'Dakar': 1, 'Senegal': 1, 'Bangkok': 1, 'Thailand': 1, 'Bristol': 1, 'UK': 2, 'Glasgow': 1, 'Berkeley': 1, 'USA': 9, 'Boulder': 1, 'El Paso': 1, 'New Orleans': 1, 'Norfolk': 1, 'Oakland': 1, 'Pittsburgh': 1, 'San Francisco': 1, 'Santa Fe': 1})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 8\n",
    "test_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('USA', 9)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 9\n",
    "test_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4472, 4948)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 10\n",
    "test_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amman', 'Byblos', 'Quito', 'Toyama']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 11\n",
    "test_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rockefeller Foundation', 22),\n",
       " ('Resilience Strategy', 20),\n",
       " ('The Rockefeller Foundation', 20),\n",
       " ('NGOs', 18),\n",
       " ('CRF', 16),\n",
       " ('PRA', 12),\n",
       " ('City', 11),\n",
       " ('NGO', 10),\n",
       " ('City Council', 10),\n",
       " ('CRO', 10)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 12\n",
    "test_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rockefeller Foundation', 22),\n",
       " ('Resilience Strategy', 20),\n",
       " ('The Rockefeller Foundation', 20),\n",
       " ('City Council', 10),\n",
       " ('Platform Partners', 9),\n",
       " ('City Resilience Framework', 8),\n",
       " ('City Resilience Framework ( CRF', 8),\n",
       " ('World Bank', 7),\n",
       " ('Steering Committee', 7),\n",
       " ('the World Bank', 6)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 13\n",
    "test_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410, 417)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 14\n",
    "test_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bruna Santos',\n",
       " 'Chico Mendes',\n",
       " 'Cristina Mendonga',\n",
       " 'Eduardo Paes',\n",
       " 'Fundagao Roberto Marinho',\n",
       " 'Instituto Pereira Passos',\n",
       " 'Kirsten Kramer',\n",
       " 'Lauretta Burke',\n",
       " 'Luciana Nery',\n",
       " 'Magdala Arioli',\n",
       " 'Martha Macedo de Lima Barata',\n",
       " 'Pensa Saia de Ideias',\n",
       " 'Rio Resiliente',\n",
       " 'Vargem Pequena',\n",
       " 'Zoraide Gomes']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST 15\n",
    "test_15"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
